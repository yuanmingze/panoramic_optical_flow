

\chapter{Approach}\label{sec:approach}

\section{Panoramic Optical Flow}


\textbf{Regular icosahedron}
a convex polyhedron with 20 faces, 30 edges and 12 vertices. 

Reference:
\href{https://en.wikipedia.org/wiki/Regular_icosahedron}{wiki}
\href{https://mathworld.wolfram.com/GnomonicProjection.html}{Gnomonic Projection}
\href{https://mathworld.wolfram.com/RegularIcosahedron.html}{Weisstein, Eric W}
\href{https://math.wikia.org/wiki/Icosahedron}{Weisstein, Eric W}

\href{https://en.wikipedia.org/wiki/Gnomonic_projection}{Weisstein, Eric W}
\href{https://www.imo.net/observations/methods/visual-observation/minor/gnomonic/}{Weisstein, Eric W}



\section{Synthesize Panoramic Optical Flow}\label{sec:app:panoof}

The real word data rich and colourful, but it very hard to estimate or measure the accurate segmentation, motion flow, e.t.c form the real word scene.
So the synthetic dataset is commonly haired to generate the ground truth data for training or performance evaluation, such as ~\cite{habitat19iccv}.

Meanwhile, the real word photo image is hard to estimate accurate optical flow.
Although KITTI~\cite{Menze2018JPRS} or MPI Sintel~\cite{Butler:ECCV:2012} pinhole image optical flow, e.t.c currently don't have any public panoramic optical flow dataset is available.

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=\linewidth]{images/synthetic_optical_flow/of_render.pdf}
	\caption{The pipeline of panoramic optical flow rendering.}
	\label{fig:approach:panoof:pipline}
\end{figure}

The synthetic panoramic optical flow rendered with on-the-shelf OpenGL render pipeline and store in the ERP image.
The input are textured 3D mesh and OpenGL's camera pose.
The process shown as the Fig.~\ref{fig:approach:panoof:pipline} composing with the following 3 steps:

\begin{enumerate}
	\item Camera Model: OpenGl render with Equirectangular projection (ERP);
	\item Warp Around: Processing the warp around at the boundary of image;
	\item Occlusion: estimate the occlusion of optical flow ;
\end{enumerate}

\subsection{Camera Model}

The traditional OpenGL rendering pipeline doesn't support the panoramic camera model and optical flow generation.
For synthesising ground truth panoramic RGB images and optical flow, we implement and hire equirectangular perspective camera model.

The equirectangular perspective panoramic camera model render the 3D mesh to  equirectangular images.
To achieve the camera model the OpenGL geometry shaders transform the 3D mesh from Cartesian coordinate system to spherical coordinate system. 
The camera mode

Furthermore, we use Replica to demonstrate. 
The Replica dataset coordinate system show as the Fig.~\ref{fig:approach:coord_hotel_00}.

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=\linewidth]{images/synthetic_optical_flow/coord_hotel_00.png}
	\caption{A boat.}
	\label{fig:approach:coord_hotel_00}
\end{figure}

And the coordinate system used in geometry OpenGL shader shown as Fig.~\ref{fig:approach:geometry_cs}.
The forward is $+z$, up is $+y$ and left is $+x$.
Meanwhile, the $\theta$ and 

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=\linewidth]{images/synthetic_optical_flow/coord_hotel_00.png}
	\caption{A boat.}
	\label{fig:approach:geometry_cs}
\end{figure}


\subsection{Warp Around}




\subsubsection{Cross Image Boundary}


\subsubsection{Poles}


\subsection{Occlusion}


\subsection{ERP Image}


