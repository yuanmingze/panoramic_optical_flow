

\chapter{Approach}

\section{Panoramic Optical Flow}


\textbf{Regular icosahedron}
a convex polyhedron with 20 faces, 30 edges and 12 vertices. 

Reference:
\href{https://en.wikipedia.org/wiki/Regular_icosahedron}{wiki}
\href{https://mathworld.wolfram.com/GnomonicProjection.html}{Gnomonic Projection}
\href{https://mathworld.wolfram.com/RegularIcosahedron.html}{Weisstein, Eric W}
\href{https://math.wikia.org/wiki/Icosahedron}{Weisstein, Eric W}

\href{https://en.wikipedia.org/wiki/Gnomonic_projection}{Weisstein, Eric W}
\href{https://www.imo.net/observations/methods/visual-observation/minor/gnomonic/}{Weisstein, Eric W}



\section{Panoramic Optical Flow Synthetic Dataset}\ref{sec:app:panoof}

The real word data rich and colourful, but it very hard to estimate or measure the accurate segmentation, motion flow, e.t.c form the read word scene.
So the synthetic dataset is commonly haired to generate the ground truth data for training or performance evaluation, such as ~\cite{habitat19iccv}.

Meanwhile, the real word photo image is hard to estimate accurate optical flow.
Although like KITTI~\cite{Menze2018JPRS} or MPI Sintel~\cite{Butler:ECCV:2012} pinhole image opical flow, e.t.c currently don't have any public panoramic optical flow dataset is available.

\subsection{Overview}

The traditional OpenGL pipeline don't support the panoramic camera model and optical flow generation.
For synthesising ground truth RGB images and optical flow, we implemented and hired an panoramic camera model.

The camera model composes with 3 parts:
\begin{itemize}
	\item Equirectangular projection;
	\item Warp Around Processing;
	\item Optical flow estimation;
\end{itemize}

\subsection{Equirectangular Projection}

The panoramic camera model render the 3D mesh to a panoramic image with the equirectangular projection.
To achieve the projection, the geometry shader transform the 3D mesh from cartesian coordinate system to spherical coordinate system.
The projection 

Furthermore, we use Replica to demonstrate. 
The Replica dataset coordinate system show as the Fig.~\ref{fig:approach:coord_hotel_00}.

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=\linewidth]{images/synthetic_optical_flow/coord_hotel_00.png}
	\caption{A boat.}
	\label{fig:approach:coord_hotel_00}
\end{figure}

And the coordinate system used in geometry OpenGL shader shown as Fig.~\ref{fig:approach:geometry_cs}.
The forward is $+z$, up is $+y$ and left is $+x$.
Meanwhile, the $\theta$ and 

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=\linewidth]{images/synthetic_optical_flow/coord_hotel_00.png}
	\caption{A boat.}
	\label{fig:approach:geometry_cs}
\end{figure}


\subsection{Warp Around Processing}




\subsubsection{Cross Image Boundary}


\subsubsection{Poles}


\subsection{Optical Flow Synthesis}



\subsubsection{Occlusion}


