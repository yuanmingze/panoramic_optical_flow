\section{Related Work}

%\subsection{Optical Flow}
\paragraph{Optical Flow}

has been a fundamental computer vision technique for decades, as it estimates dense correspondences between two input images \cite{BakerSLRBS2011,MenzeHG2018}.
These correspondences can be used to identify object or camera ego-motion, and optical flow thus finds many applications in robotics, scene understanding, geometry reconstruction etc.
%
Traditional optical flow methods are formulated using energy minimization based on photoconsistency and regularisation with a smoothness term \cite{KroegTDV2016, HornS1981, LucasK1981, BlackA1991}.
%
\citet{BroxBPW2004} proposed a warping-based method that refines optical flow estimations in a coarse-to-fine fashion.
% with multi-iteration from previous iteration optical flow warped image.
%
\citet{SunRB2014} uses a median filter post-processing step to produce sharper object boundaries in the optical flow fields.


In recent years, learning-based methods have defined a new state of the art in optical flow estimation.
%
%Supervised Learning:
%Leveraged by the machine learning method, the supervised learning optical flow methods were proposed.
%
The first methods were based on supervised learning, generally on synthetic training data.
%
FlowNet \cite{DosovFIHHGSCB2015} lifts the correlation operation into feature space, and uses a multi-scale architecture to effectively predict optical flow from two input images.
%
FlowNet2 \cite{IlgMSKDB2017} introduces image warping between multiple cascaded FlowNets to increase the accuracy of large pixel motion.
%
PWC-Net \cite{SunYLK2020} incorporates the best practices of traditional optical flow methods into a neural network: pyramid processing, image warping, and cost volume processing.
%
RAFT \cite{TeedD2020a} employs a recurrent network to iteratively estimate optical flow from the 4D correlation volume between all pairs of pixels. %, with significant improvements over the state of the art.
%
%%Unsupervised Learning:
\citet{AleotPM2021} propose a data generation method using monocular depth estimation to synthesise a second view from a single input image.
This enables self-supervised training of existing optical flow methods.


% 360 optical flow
Virtually all optical flow methods focus on perspective input images, although spherical images have recently received more attention.
%
%The CNN based panoramic optical methods \citet{ArtizZAD2021} and \citet{BhandZY2021}
To this end, recent approaches by \citet{ArtizZAD2021} and \citet{BhandZY2021}
transfer the architecture and weights of pre-trained networks \cite{DosovFIHHGSCB2015,HuiTC2018} to spherical images in the equirectangular projection (ERP) format.


\subsection{Panoramic Image Processing}

%% Application areas.
Panoramic (aka 360° or \emph{spherical}) images have been used in a wide variety of application areas, including
depth estimation \cite{ImHRJCK2016, JiangSZDH2021, LaiXLL2019, SunSC2021, WangHCLYSCS2018, WangSTCS2020, WangYSCT2020, ZioulKZD2018, ZioulKZAD2019},
room layout estimation \cite{WangYSCT2021, Tran2021, EderMG2019, FernaFPDCG2020, JinXZZTXYG2020, SunSC2021, ZengKG2020},
semantic segmentation \cite{LeeJYJY2019, SunSC2021, YangZRHS2021, ZhangLSC2019},
novel-view synthesis \cite{BerteYLR2020, HuangCCJ2017, MatzeCEKS2017, XuZXTG2021} and so on.
%
%% Problems.
%The panoramic image format converts the 3D scene to a 2D image with the non-linear project, but it introduces distortion in the 2D image, e.g. the equirectangular image format has larger distortion especially on the top and bottom of the image.
The key problem when working with spherical images is to project them onto a regular 2D pixel grid for easy processing, as any projection introduces some kind of distortion – similar to maps of the world.
%
For example, spherical images in ERP format show significant distortions near the top/bottom image edges, which represent the two poles.


% sovle with projection method
%% cubemap projection
\citet{SunSC2021} proposed HoHoNet is a versatile method, their LHFeat is squeezed per-column feature, used to predict whole image information (depth map, semantic segmentation and layout reconstruction) with IDCT. 
\citet{WangYSCT2020}
\citet{WangHCLYSCS2018}
\citet{ChengCDWLS2018}


%% gnomonic projection
\cite{CoorsCG2018} use Gnomonic Projection to directly sample data from panoramic image, in this way they transform the omnidirectional sampling to perspective's.


%% Icosahedron
\citet{EderPVBF2019}
\citet{EderSLF2020}
Icosahedron is used to averagely sampling from the panoramic image, to make less overlap area between each sampling area.
\citet{LuoZSX2019}
\citet{ZhangLSC2019}
\citet{LeeJYJY2019}

% sovle with on CNN area
\citet{GkitsZAZD2020}
%% kernel transfrom 
\citet{SuG2019}
%% rotation invariance 
\citet{CohenGKW2018}
\citet{JiangHKPMN2019}

\subsection{Panoramic Datasets}

% 360 Image dataset:
%% Real-world
- MatterportLayout dataset: https://github.com/ericsujw/Matterport3DLayoutAnnotation, labeled scene

%% synthetic dataset (CAD dataset)
The real word data rich and colourful, but it is very hard to estimate or measure the accurate segmentation, motion flow, etc. form the real word scene.

- 360D dataset:
- Structured3D: https://structured3d-dataset.org/, synthetic dataset,room layout estimation
- Omnidirectional Stereo Dataset: http://cvlab.hanyang.ac.kr/project/omnistereo/
- Realtor360: 
- SUMO

% 3D Mesh dataset:
So the 3D dataset is commonly haired to generate the ground truth data for training or performance evaluation, such as Habitat \cite{SavvaKMZWJSLKMPB2019}.

%% laser scanned
- Stanford2D3D \cite{ArmenSZS2017}
- Matterport3D ~\cite{ChangDFHNSSZZ2017}
- Replica ~\cite{StrauWMCWGEMRVCYBYPYZLCBGMPSBSNGLN2019}
- iGibson (Gibson)

%% CAD dataset

Meanwhile, the real word photo image is hard to estimate accurate optical flow.
 currently don't have any public panoramic optical flow dataset is available.
