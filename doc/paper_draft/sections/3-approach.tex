\section{Approach}\label{sec:approach}

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.95\linewidth]{images/method_pipeline_1.pdf}
	\caption{\label{fig:approach:pipeline}%
		Method overview.
		The input is a pair of equirectangular images, $I_t$ and $I_{t+1}$, and the output is the optical flow $\mathcal{F}_t$ from $I_t$ and $I_{t+1}$.
		It composed with 3 steps: (1) ? (2) ?}
\end{figure}

The method proposes a tangent image global warping optical flow method to mitigate the equirectangular distortion and large motion between two images, meanwhile, the backbone optical flow method hired off-the-shelf and general optical flow method $M_{\mathcal{F}}$.
The optical flow $\textbf{f}$ is estimated pixel displacement vector $f(u,v)$ for each pixel $(u,v)$ in a sequence image pair from source image $I_{src}$ to target image $I_{tar}$.

As shown in the overview diagram \cref{fig:approach:pipeline} our method compose with 3 steps:
1) Estimate the optical flow $\bar{\mathcal{F}}_t$ from $I_{t}$ to ${I_{t+1}}$, then rotate the $I_{t+1}$ toward to $I_{t}$ with the $\bar{R}$ esitmation form $\mathcal{F}_t$ to generate ${\bar{I}}_{t+1}$;
2) Estimate the optical flow ${\hat{\mathcal{F}}}_t$ from $I_{t}$ to ${\bar{I}}_{t+1}$ with CubeMap projection method $f??$, then rotate the  ${\bar{I}}_{t+1}$ toward to $I_t$ with the $\hat{R}$ esitmated from ${\hat{\mathcal{F}}}_t$ to generate ${\hat{I}}_{t+1}$;
3) Estimate the optical flow $\tilde{\mathcal{F}}_t$ from $I_{t}$ to ${\hat{I}}_{t+1}$ with icoshedron porject, then warp  the $\tilde{\mathcal{F}}_t$ with invert of $\bar{R}$ and $\hat{R}$ to generate finnally optical flow $\mathcal{F}_t$.

% why do that
Comparing to the perspective image the equirectangular image has distortion especially at the top and bottom.
We using gnomonic projection to \CR{locally?} undistort the image, and use cubemap and icosahedron projections to uniformly sample the ERP image with varying FoV (\cref{sec:approach:projstit}).

Because the tangent image \TODO{...}
Use optical flow warping method to align the source and target images before
Finaaly Accumulate all step optical flow together with the \TODO{...} (\cref{sec:approach:warping}).

%The optical flow method 
%\todolist{Rough and warp based method. Why not warp base method? CubeMap warp the target image, and Ico compute the cubemap warpped image. Finally, accumualte all optical flow together.}


\subsection{Panoramic Optical Flow Definition}
\label{sec:approach:definition}

Different from the perspective image, the panoramic image is enclosed in any direction on the image,  and the coordinate is continuous.
So the panoramic optical flow is continuous, even the pixel's motion vector is overflowed the image size.
It's different from perspective image optical which ~\cite{??}. 
This is one reason the perspective image optical flow method can not track well the pixel moving out the equirectangular image boundary.

But the continuous optical flow will introduce ambiguity, 
%the stright line in the 3D space will project to a segement on one great circle.
there are two paths from the source point to the target point along the great-circle on the sphere ~\cite{??}.
To define the panoramic optical flow on equirectangular image format, we propose the following assumes:
the pixel motion is always moving along the the shortest path of great circle;

% in the ERP image range ?
The panoramic image projection to equirectangular image, the pixel along the x-axis is not continuous, but along the y-axis is still continuous. When the pixel position si beyond the  ${Imagewidth -1}$, the pixel position will convert to left again.
But the pixel along the y-axis is continuous.
the pixel motion is always along , which is not larger than 0.5$\pi$.

\TODO{Summarize the benefit of this expression? Why use the warp-around optical flow?}
Sample is continue 
visualisation friendly
close the spherical coordinate expression

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.45\linewidth]{images/wrap-around-0.jpg}
	\caption{Panoramic Optical Flow.}
	\label{fig:app:warparound}
\end{figure}


\subsection{Optical Flow Warping}
\label{sec:approach:warping}

The $f(u,v)$ compose with $f_1(u,v)$ and $f_2(u,v)$, which is the displacement in image's horizontal direction $x$ and vertical direction $y$ respectively.
Optical flow 
$I_{tar}(u',v')$ is corresponding the pixel $I_{src}(u + f_1(u,v), v + f_2(u,v))$.


The tangent image which projected from a distorted image to a plain image have been proposed image segmentation and on \cite{eldercvpr2020} \CR{Do you mean \cite{EderSLF2020}?}

But comparing to a panoramic image the tangent image's available viewport is small, not larger than $\pi$ and just $\frac{\pi}{2}$ in cubemap projection.

Inspired by the warp base optical flow \cite{?}, and coarse to fine 

Use panoramic images optical flow estimation rotation to roughly align the two images.

\todolist{How to convert the rough optical flow to rotation?}

The image warp, the rotation to warp the image, alignt the 

The optical flow warping, to warp the final optical flow to restore the original images optical flow.


\subsection{Projection \& Stitching}
\label{sec:approach:projstit}

The $\hat{\mathcal{F}_t}$ and $\tilde{\mathcal{F}}_t$ is panoramic optical flow stitching from CubeMap and Icosehedron face image (tangent image) optical flow.

The meth0d composes with 3 steps:
 equirectangular image projection project part of the images pair to perspective images, e.g. tangent images, respectively to get ride of distortion;
 perspective image optical flow estimation to calculate each tangent image optical flow;
 and optical flow stitching to blend each faces' optical flow back to equirectangular format. 
 
 The perspective image optical flow method is off-the-shelf method which is general to any optical flow method.

The RGB image projection project the point from sphere surface to tangent plan to generate perspective image.~\cite{??}
The optical flow stitching 

\textbf{Equirectangular Image Projection}

% why 

The equirectangular RGB image projection use gnomonic projection to generate the tangent images ~\cite{??}, which is perspective image doesn't have distortion.

When hire the gnomonic porject to project the sphere surface to know the 

To make the tangent images uniform sample the sphere surface, the tangent points should uniformly distribute on the surface of the unit sphere.~\cite{??}
For cover different we select the 
The regular polygon ~\cite{??} 

% how to select the samplin points?

Set the tangent point $S$ as the centre point of the projection, who longitude and latitude is $(\theta_0, \phi_0)$,
The sphercial points is $(\theta, \phi)$

project the panoramic image to perspective images.

%Tangent/Center points selection.
Use cubemap or Regular icosahedron, which is a convex polyhedron with 20 faces, 30 edges and 12 vertices.

For the perspective image to cover different field of view (FoV)  to estimate the different scale motion, the sampling point selection regular cubemap and regular icosahedron's inscribe sphere points, which are the most common regular polygon and have different FoV. ~\cite{xxx}

The cubemap's face has wider FoV than the icosahedron's face, which can estimate a larger span motion vector from the tangent image, but Its PPI is smaller than the icosahedron's when they are in the same resolution.

\TODO{CubeMap and ICO's face FOV range. And diagram to show the .}

\textbf{Perspective optical flow stitching}

Each tangent image optical flow estimation is separated, make the faces overlap area's optical flow is not consistent.
So when stitch each faces optical flow to equirectangular format, we compute a confidence weight to each perspective images. 

\begin{equation}
W_{face} =
\end{equation}


The weight compose with 

\TODO{How to compute the weight and blending? Equation, and Visualized different weight and blend result, and show each face's optical flow.}

