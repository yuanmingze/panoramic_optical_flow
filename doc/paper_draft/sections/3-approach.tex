\section{Approach}\label{sec:approach}

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.95\linewidth]{images/method_pipeline_1.pdf}
	\caption{Method overview. The input is a pair of equirectangular images sequence $I_t$ and $I_{t+1}$, output is the optical flow $\mathcal{F}_t$. The $\oplus$ and  $\ominus$ are the image forward rotation operation and optical flow backward rotation operation ~\cref{sec:approach:warping}, respectively. The green box estimate the rotation from optical flow motion vector.}
	\label{fig:approach:pipeline}
\end{figure}

Our method comprises a global rotation warping and tangent-image-based panoramic optical flow method to mitigate the distortions in equirectangular image and the large displacements of pixels.
At the same time, our high-level approach generalises to any off-the-shelf perspective optical flow method, and thus will benefit from future improvements in optical flow methods.


% overview method
As shown in \cref{fig:approach:pipeline}, our method comprises three steps:
%
(1)~We estimate the optical flow $\bar{\mathcal{F}}_t$ from image $I_{t}$ to image ${I_{t+1}}$, followed by rotating $I_{t+1}$ towards to $I_{t}$ based on the rotation estimate $\bar{R}$ from the flow $\mathcal{F}_t$, which generates the warped ERP image ${\bar{I}}_{t+1}$ (see \cref{sec:approach:warping}).
%
(2)~We estimate the panoramic optical flow ${\hat{\mathcal{F}}}_t$ from $I_{t}$ to ${\bar{I}}_{t+1}$ based on cubemap projection optical flow (see \cref{sec:approach:projstit}), and then rotate the image ${\bar{I}}_{t+1}$ according to the rotation $\hat{R}$ estimated from the cubemap flow ${\hat{\mathcal{F}}}_t$ to generate ${\hat{I}}_{t+1}$.
%
(3)~We estimate the fine-scale flow $\tilde{\mathcal{F}}_t$ from $I_{t}$ to ${\hat{I}}_{t+1}$ using icosahedron projection optical flow (see \cref{sec:approach:warping}), then backward-rotate the fine-sacle flow $\tilde{\mathcal{F}}_t$ by rotations $\bar{R}$ and $\hat{R}$ to generate the final 360° optical flow $\mathcal{F}_t$.
\looseness-1

% 
Compared to perspective images, equirectangular images are continuous in all direction.
In \cref{sec:approach:definition}, we analyse and define the panoramic optical flow.
%
To solve the equirectangular image distortion, especially at the top and bottom, our method employs gnomonic projection to project the equirectangular image to tangent image~\cite{EderSLF2020}.
We use cubemap and regular icosahedron faces to uniformly sample the equirectangular image to solve this problem (see \cref{sec:approach:projstit}).
%
However, compared to a panoramic image, a tangent image has a smaller field of view, not larger than $\pi$ and just $\frac{\pi}{2}$ for cubemap projection (without padding).
To compensate for the tangent images' narrow field of view, the global rotation operation is used on the target image $I_{t+1}$ to align it with the source image $I_t$ (\cref{sec:approach:warping}).


\subsection{Panoramic Optical Flow Definition}
\label{sec:approach:definition}

Spherical image coordinates are continuous in any direction on the image, e.g. pixel locations overflowing the image width will wrap around to the other side of the image.
%
If panoramic optical flow follows an object, a pixel's motion vector can fall outside the image boundary.
%It's different from perspective image optical which ~\cite{??}. 
This is one reason that perspective optical flow methods cannot track pixels moving outside the equirectangular image boundary, because they do not support the horizontal coordinate wrap-around, as illustrated in \cref{fig:app:warparound}.
%\TODO{Add image two show the warp-around optical flow and un-warp-around optical flow.}
%
However, this introduces an ambiguity into 360° optical flow estimation, 
%the straight line in the 3D space will project to a segment line on one great circle.
as there is more than one path from the source point to the target point along a great-circle on the sphere:
usually there is one shorter and one longer path.\footnote{One could also travel along the great circle a few more times, but these paths are getting longer and longer.}
%
To uniquely define 360° optical flow in the equirectangular image format, we define the optical flow to follow the shortest path from source to target along the great circle between them.
%propose the following assumes: the pixel motion is always moving along the shortest path of great circle;
%
This naturally limits the maximum flow magnitude to $\leq$180°.

\CR{I don't understand this paragraph. What information does it add on top of the previous paragraph?}
% in the ERP image range ?
The panoramic image projection to equirectangular image, the pixel along the x-axis is not continuous, but along the y-axis is still continuous. When the pixel position is beyond the  ${Imagewidth -1}$, the pixel position will convert to left again.
But the pixel along the y-axis is continuous.
The pixel motion is always along, which is not larger than 0.5$\pi$.
% the benefits of ERP optical flow
\TODO{Summarize the benefit of this expression? Why use the warp-around optical flow?}
%Sample is continue 
%visualisations friendly
%close the spherical coordinate expression


\begin{figure}%[hbt!]
	\centering
%	\begin{center}
	\subfigure[Source Image]{\includegraphics[width=0.26\linewidth]{images/wraparound/src_image.png}}
	\subfigure[Target Image]{\includegraphics[width=0.26\linewidth]{images/wraparound/tar_image.png}} 
	\subfigure[Perspective Optical Flow]{\includegraphics[width=0.26\linewidth]{images/wraparound/src2tar.png}}
	\subfigure[Warp Around]{\includegraphics[width=0.19\linewidth]{images/wraparound/wraparound.png}}
%	\end{center}
	\caption{\label{fig:app:warparound}%
		360° optical flow illustrated:
		A bunny moves from (a) to (b) within an ERP image.
		(c) Perspective optical flow methods estimate the bunny's motion from the right to the left via the front.
		(d) However, the shortest path for the bunny to move is along the back wrap-around.		
	}
\end{figure}


\subsection{Projection \& Stitching}
\label{sec:approach:projstit}

% why need projection and stitch?
To mitigate the ERP image distortion, we hire the perspective image optical flow methods with gnomonic projection to un-distort the ERP image in both cubemap and icosahedron sampling.
% how to do it 
The cubemap and icosahedron optical flow methods composes with 3 steps:
project the ERP image with gnomonic projection \cite{?} to generate perspective image i.e. tangent images, with cubemap and icosahedron sampling respectively \cite{?}\cite{?};
use perspective image optical flow method to estimate each tangent image optical flow;
stitch each tangent images optical flow back to ERP format.
% more detail
The perspective image optical flow method is off-the-shelf method which is general to any optical flow method.

\textbf{Equirectangular Image Projection}.
% tangent image generation
As \cite{ZhaoYZLBT2020} the gnomonic projection is used to generate the tangent images ~\cite{??}, which is a perspective image projected from the sphere surface at tangent point on the united sphere surface.
% sampling points selection (Tangent/Center points selection.)
With different tangent point selection, the tangent images cover the different spherical surface area and image field of view (FOV).
%
For estimating the multi-scale motion and uniform sample the sphere surface, the tangent points selected with inscribe sphere points of regular cubemap and regular icosahedron, which are the most common convex regular polyhedron and have different FOV~\cite{?}.
%
The tangent image of cubemap has wider FOV than the tangent image of icosahedron, so cubemap can estimate a larger span motion vector from the tangent image, but its PPI is smaller than the icosahedron's when they are in the same tangent image resolution.
% tangent images padding
To increase the tangent images FOV and improve the optical flow near the image boundary ~\cite{?}, we use tangent image padding to increase more area and extend the tangent image boundary, shown as \cref{fig:approach:projection}.

\begin{figure}[hbt!]
	\begin{center}
		\subfigure[Gnomonic Projection]{\includegraphics[width=0.43\linewidth]{images/tangent_image/tangent_image_6.png}}
		\subfigure[Target Image Padding]{\includegraphics[width=0.43\linewidth]{images/tangent_image/tangent_image.pdf}} 
	\end{center}
	\caption{\label{fig:approach:projection}
		Image Cubemap and Ico projection with padding. \TODO{Image show the cubemap and ico projection result and sampling points \& padding area with padding size.}}
\end{figure}

\textbf{Perspective optical flow stitching}.
% how to stitch
%The $\hat{\mathcal{F}_t}$ and $\tilde{\mathcal{F}}_t$ is panoramic optical flow stitching from CubeMap and Icosahedron face image (tangent image) optical flow.
Each tangent image optical flow estimation is separated, make the faces overlap area's optical flow is not consistent.
So when stitch each faces optical flow to equirectangular format, we compute a confidence weight to each perspective images.
% blending 
The weight compose with 
The padding area need blending
% blending method

\begin{equation}
W_{face} =
\end{equation}

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.35\linewidth]{example-image}
	\caption{Optical flow stitching blending weight visualization.\TODO{Visualized different weight and blend result, and show each face's optical flow.}}
	\label{fig:approach:blendweight}
\end{figure}

\subsection{Global Rotation Warping}
\label{sec:approach:warping}

Inspired by the warping-based optical flow~\cite{BroxBPW2004}, we use the global rotation to align the $I_{t+1}$ to $I_{t}$ for compensation the tangent image small FOV and reduce the large pixel motion span.
The global rotation $R$ compose of horizontal and vertical rotation extracted from the panoramic optical flow to rotate all pixels in the equirectangular image.
The horizontal rotation extract from the optical flow horizontal part i.e. $\mathcal{F}_u$ with the equation $\frac{2\pi}{n\cdot W}\sum\mathcal{F}_u$, the $n$ is image pixel number and $W$ is image width in pixel.
The vertical rotation extract from the vertical part i.e. $\mathcal{F}_v$ with the equation $\frac{2\pi}{n\cdot H}\sum\mathcal{F}_v$, $H$ is the image height.
% it's the noly 20% middle column of the $\mathcal{F}_v$

\textbf{Image Global Rotation Warping.}
After extract the global rotation $R$ from optical flow, rotate the target image $I_{t+1}$ with $R$ from alignment to the source image $I_{t}$ with the equirectangular image rotation in 3D space. ~\cite{ZioulKZAD2019}.
%
The global rotation warping based on the coarse to fine principle, 
Firstly, use panoramic images optical flow estimated $\bar{R}$ to roughly align the $I_{t+1}$ for getting rid of the ego-motion, then use the cubemap optical flow to fine-tune the alignment.

\textbf{Panoramic Optical Flow Global Rotation Warping.}
To restore the $\mathcal{F}$ from the icosahedron optical flow $\tilde{\mathcal{F}}$, the end point of $\tilde{\mathcal{F}}$ should trace to the pixel position in $I_{t+1}$.
% 
When estimating the optical flow only the target image $I_{t+1}$ is warped, so just need to rotate the end point of $\tilde{\mathcal{F}}_t$, i.e $\tilde{\mathcal{F}}^{EP}_t$. 
%
To rotate the panoramic image, first transform it to 3D space with $\mathcal{P}$, and back to equirectangular image with $\mathcal{P}^{-1}$.

\begin{equation}\label{equ:approach:globalwarp}
\begin{split}
	\mathcal{F}_{(i,j)} &= \mathcal{F}^{EP}_{(i,j)} - (i,j)  \\
				&= \mathcal{P}^{-1} \left( \hat{R}^{-1} \cdot \bar{R}^{-1} \cdot \mathcal{P}(\tilde{\mathcal{F}}^{EP}_{(i,j)}) - (i,j)\right)
\end{split}
\end{equation}
