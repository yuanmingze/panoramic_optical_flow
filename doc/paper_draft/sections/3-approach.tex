\section{Approach}\label{sec:approach}

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.95\linewidth]{images/method_pipeline_1.jpg}
	\caption{Method overview. The input is a pair of equrictangular images $I_t$ and $I_{t+1}$, output is the optical flow $\mathcal{F}_t$ from  $I_t$ and $I_{t+1}$. It compused with 3 steps: (1) ? (2) ?}
	\label{fig:approach:pipeline}
\end{figure}

The method proposes a tangent image global warping optical flow method to mitigate the equirectangular distortion and large motion between two images, meanwhile, the backbone optical flow method hired off-the-shelf and general optical flow method $M_{\mathcal{F}}$.

As shown in the overview diagram Fig.~\ref{fig:approach:pipeline}, our method compose with 3 steps:
1) Estimate the optical flow $\bar{\mathcal{F}}_t$ from $I_{t}$ to ${I_{t+1}}$, then rotate the $I_{t+1}$ toward to $I_{t}$ with the $\bar{R}$ esitmation form $\mathcal{F}_t$ to generate ${\bar{I}}_{t+1}$;
2) Estimate the optical flow ${\hat{\mathcal{F}}}_t$ from $I_{t}$ to ${\bar{I}}_{t+1}$ with CubeMap projection method $f??$, then rotate the  ${\bar{I}}_{t+1}$ toward to $I_t$ with the $\hat{R}$ esitmated from ${\hat{\mathcal{F}}}_t$ to generate ${\hat{I}}_{t+1}$;
3) Estimate the optical flow $\tilde{\mathcal{F}}_t$ from $I_{t}$ to ${\hat{I}}_{t+1}$ with icoshedron porject, then warp  the $\tilde{\mathcal{F}}_t$ with invert of $\bar{R}$ and $\hat{R}$ to generate finnally optical flow $\mathcal{F}_t$.




The optical flow method 

%\todolist{Rough and warp based method. Why not warp base method? CubeMap warp the target image, and Ico compute the cubemap warpped image. Finally, accumualte all optical flow together.}

the Icosahedron  aligned target ERP image with Icosahdron, ;
Accumulate all step optical flow together.
using gnomoinic projection to undistrot the , with uniform sample the ERP image,
to align the source and target images beore

The optical flow $\textbf{f}$ is estimated pixel displacement vector $f(u,v)$ for each pixel $(u,v)$ in a sequence image pair from source image $I_{src}$ to target image $I_{tar}$.

The $f(u,v)$ compose with $f_1(u,v)$ and $f_2(u,v)$, which is the displacement in image's horizontal direction $x$ and vertical direction $y$ respectively.
Optical flow 

$I_{tar}(u',v')$ is corresponding the pixel $I_{src}(u + f_1(u,v), v + f_2(u,v))$.

\textbf{360 Optical Flow Expression (Wrap-around)}
\todolist{GT data how to process the Warp Around, Cross Image Boundary.Why use the without warp around optical flow?}

The panoramic image projection to equirectangular image, the pixel along the x-axis is not continuous, but along the y-axis is still continuous. When the pixel position si beyond the  ${Imagewidth -1}$, the pixel position will convert to left again.
But the pixel along the y-axis is continuous.
\todolist{add a diagram to explain the continuation.}

\begin{figure}[hbt!]
	\centering
	\includegraphics[width=0.45\linewidth]{images/wrap-around-0.jpg}
	\caption{Optical Flow wrap-around.}
	\label{fig:app:warparound}
\end{figure}

The panoramic image's $x$ and $y$ is continual, in this way it's reasonable the pixel coordinate 0 exceed the range of image pixel $([0, image\_width), [0, image\_height))$. 

The range of optical flow is 

So the 360 optical flow is different with perspective image optical flow in the 

, 360 optical flow is  in 

So there are two-kinds of expression.

One kind optical flow is just in target image range $[0, image_width - 1]$, which do not take the wrap around into account.

So the range of optical flow is 
Another's target image range is $[- n * image_width, + n * image_width]$


\subsection{Optical Flow Warping}

The tangent image which projected from a distorted image to a plain image have been proposed image segmentation and on ~\cite{eldercvpr2020}

But comparing to a panoramic image the tangent image's available viewport is small, not larger than $\pi$ and just $\frac{\pi}{2}$ in CubeMap projection.

Inspired by the warp base optical flow \cite{?}, and coarst to fine 

Use panoramic images optical flow estimation rotation to roughly align the two images.

\todolist{How to convert the rough optical flow to rotation?}

The image warp, the rotation to warp the image, alignt the 

The optical flow warping, to warp the final optical flow to restore the original images optical flow.


\subsection{Projection \& Stitching}


The $\hat{\mathcal{F}_t}$ and $\tilde{\mathcal{F}}_t$ is panoramic optical flow stitching from CubeMap and Icosehedron face image (tangent image) optical flow.

The methed composes with 3 steps:
 equirectangular image projection project part of the images pair to perspective images, e.g. tangent images, respectively to get ride of distortation;
 perspective image optical flow estimation to calcuate each tangent image optical flow;
 and optical flow sitching to blend each faces' optical flow back to equirectangular format. 
 
 The perspective image optical flow method is off-the-shelf method which is general to any optical flow method.

The RGB image projection project the point from sphere surface to tangent plan to generate perspective image.~\cite{??}
The optical flow stitching 

\textbf{Equirectangular Image Projection}

% why 

The equirectangular RGB image projection use gnomonic projection to generate the tangent images ~\cite{??}, which is perspective image doesn't have distortation.

When hire the gnomonic porject to project the sphere surfce to know the 

To make the tangent images uniform sample the sphere surface, the tangent points should uniformly distribute on the surface of the unit sphere.~\cite{??}
For cover differen we select the 
The regular polygon ~\cite{??} 

% how to select the samplin points?

Set the tangent point $S$ as the centre point of the projection, who longitude and latitude is $(\theta_0, \phi_0)$,
The sphercial points is $(\theta, \phi)$

project the panoramic image to perspective images.

%Tangent/Center points selection.
Use cubemap or Regular icosahedron, which is a convex polyhedron with 20 faces, 30 edges and 12 vertices.

For the perspective image to cover different field of view (FoV)  to estimate the different scale motion, the sampling point selection regular cubemap and regular icosahedron's inscribe sphere points, which are the most common regular polygon and have different FoV. ~\cite{xxx}

The cubemap's face has wider FoV than the icosahedron's face, which can estimate a larger span motion vector from the tangent image, but Its PPI is smaller than the icosahedron's when they are in the same resolution.

\TODO{CubeMap and ICO's face FOV range. And diagram to show the .}

\textbf{Perspective optical flow stitching}

Each tangent image optical flow estimation is separated, make the faces overlap area's optical flow is not consistent.
So when stitch each faces optical flow to equirectangular format, we compute a confidence weight to each perspective images. 

\begin{equation}
W_{face} =
\end{equation}


The weight compose with 

\TODO{How to compute the weight and blending? Euqation, and Visualized different weight and blend result, and show each face's optical flow.}

